{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mount your Drive"
      ],
      "metadata": {
        "id": "Tk0J-gBqNMYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11z0sFfCRKEO",
        "outputId": "bb0ac2cb-02f7-4595-c714-2f99f4436046"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required Libraries"
      ],
      "metadata": {
        "id": "SmlkdYYVNVHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import wavfile\n",
        "import warnings\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "aArPubdtRPJy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract the zip file"
      ],
      "metadata": {
        "id": "DHP82MU2NQ9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_file_path = '/content/drive/MyDrive/004_Aravind/Language Identification/Dataset/language-audio-data.zip'\n",
        "target_dir = 'final_data'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(raw_file_path,\"r\") as zip_f:\n",
        "    zip_f.extractall(target_dir)"
      ],
      "metadata": {
        "id": "1IuIuHeHTUoF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the number of files in each class"
      ],
      "metadata": {
        "id": "Z2-yMd9nNYYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dir1 = os.path.join(target_dir,'language-audio-data')\n",
        "os.listdir(audio_dir1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6_adToBYWQt",
        "outputId": "2eeb5160-60ef-4a5b-e3a9-6e8c7ad796fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hindi', 'Tamil', 'Kannada', 'Telugu']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = []\n",
        "for i in os.listdir(audio_dir1):\n",
        "    classes.append(i)\n",
        "    class_path = audio_dir1 + '/' + str(i)\n",
        "    audio_clips = os.listdir(class_path)\n",
        "    print(f\"No. of .wav files in audio {i} folder = \",len(audio_clips))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeel4v71YcLG",
        "outputId": "3e6a3f65-0eaf-4def-badc-5f5dab5ae651"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of .wav files in audio Hindi folder =  7001\n",
            "No. of .wav files in audio Tamil folder =  6885\n",
            "No. of .wav files in audio Kannada folder =  7249\n",
            "No. of .wav files in audio Telugu folder =  7119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert MP3 to wave"
      ],
      "metadata": {
        "id": "Pt3MqMYdNbmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from os import path\n",
        "# from pydub import AudioSegment\n",
        "\n",
        "# os.makedirs(\"final_wav\", exist_ok=True)\n",
        "\n",
        "# for folder in os.listdir(audio_dir1):\n",
        "#     class_path = audio_dir1 + '/' + str(folder)\n",
        "#     for count, files in enumerate(os.listdir(class_path)):\n",
        "#       src = f\"{audio_dir1}/{folder}/{files}\"\n",
        "#       file_name = f\"{folder}-{str(count)}.wav\"\n",
        "#       dst = f\"final_wav/{folder}\"W\n",
        "#       os.makedirs(dst, exist_ok=True)\n",
        "#       dst = f\"final_wav/{folder}/{file_name}\"\n",
        "#       sound = AudioSegment.from_mp3(src)\n",
        "#       sound.export(dst, format=\"wav\")"
      ],
      "metadata": {
        "id": "yvRyWjpmas2_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Metadata for your dataset"
      ],
      "metadata": {
        "id": "c1_9-6lwNh9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename the files\n",
        "\n",
        "for folder in os.listdir(audio_dir1):\n",
        "    class_path = audio_dir1 + '/' + str(folder)\n",
        "    for count, files in enumerate(os.listdir(class_path)):\n",
        "        try:\n",
        "            dst = f\"{folder}1-{str(count)}.wav\"\n",
        "            src =f\"{audio_dir1}/{folder}/{files}\"  \n",
        "            dst =f\"{audio_dir1}/{folder}/{dst}\"\n",
        "            os.rename(src, dst)\n",
        "        except FileExistsError:\n",
        "             pass"
      ],
      "metadata": {
        "id": "UDirqdIEdq3r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### create meta data\n",
        "\n",
        "wav_dir = '/content/final_data/language-audio-data'\n",
        "\n",
        "metadata = {}\n",
        "for label in os.listdir(wav_dir):\n",
        "    class_path = wav_dir + '/' + str(label)\n",
        "    audio_clips = os.listdir(class_path)\n",
        "    for filename in audio_clips: \n",
        "        metadata[filename] = label\n",
        "\n",
        "# Create a metadata csv file\n",
        "metadata = pd.DataFrame.from_dict(metadata, orient='index').reset_index().sort_values(by=0)\n",
        "metadata.columns = ['filename', 'foldername']\n",
        "le = preprocessing.LabelEncoder()\n",
        "metadata['labels'] = le.fit_transform(metadata.foldername)\n",
        "metadata.to_csv('metadata.csv', index=False)\n",
        "metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "deh27IoZdq_A",
        "outputId": "e9e52d8f-8ace-4d58-8f52-807f5c95b6f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               filename foldername  labels\n",
              "0       Hindi1-2561.wav      Hindi       0\n",
              "4674    Hindi1-5263.wav      Hindi       0\n",
              "4673    Hindi1-6310.wav      Hindi       0\n",
              "4672    Hindi1-1316.wav      Hindi       0\n",
              "4671    Hindi1-2108.wav      Hindi       0\n",
              "...                 ...        ...     ...\n",
              "23501  Telugu1-4386.wav     Telugu       3\n",
              "23500  Telugu1-5588.wav     Telugu       3\n",
              "23499  Telugu1-5844.wav     Telugu       3\n",
              "23510  Telugu1-6027.wav     Telugu       3\n",
              "28253  Telugu1-6930.wav     Telugu       3\n",
              "\n",
              "[28254 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77230e97-34d1-41d3-a905-22c79357bb4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>foldername</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hindi1-2561.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4674</th>\n",
              "      <td>Hindi1-5263.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4673</th>\n",
              "      <td>Hindi1-6310.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4672</th>\n",
              "      <td>Hindi1-1316.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4671</th>\n",
              "      <td>Hindi1-2108.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23501</th>\n",
              "      <td>Telugu1-4386.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23500</th>\n",
              "      <td>Telugu1-5588.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23499</th>\n",
              "      <td>Telugu1-5844.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23510</th>\n",
              "      <td>Telugu1-6027.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28253</th>\n",
              "      <td>Telugu1-6930.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28254 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77230e97-34d1-41d3-a905-22c79357bb4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77230e97-34d1-41d3-a905-22c79357bb4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77230e97-34d1-41d3-a905-22c79357bb4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the mappings \n",
        "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(le_name_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qo2blzPjDPR",
        "outputId": "299431b9-fd78-4c0e-99b9-a989e8f6c5c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Hindi': 0, 'Kannada': 1, 'Tamil': 2, 'Telugu': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom PyTorch Dataset"
      ],
      "metadata": {
        "id": "Y-J5p46KpL6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import-libraries\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchaudio\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kMKYVAyXrrlG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IndianLanguageDataset(Dataset):\n",
        "  def __init__(self, metadata, audio_dir, target_sample_rate, num_samples, transformation):\n",
        "    self.annotations = pd.read_csv(metadata)\n",
        "    self.audio_dir = audio_dir\n",
        "    self.target_sample_rate = target_sample_rate\n",
        "    self.num_samples = num_samples\n",
        "    self.transformation = transformation\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    audio_sample_path = self._get_audio_sample_path(idx)\n",
        "    label = self._get_audio_sample_label(idx)\n",
        "    signal, sr = torchaudio.load(audio_sample_path)\n",
        "    signal = self.resample_audio(signal, sr)\n",
        "    signal = self.mix_down_channels(signal)\n",
        "    signal = self.cut_if_needed(signal)\n",
        "    signal = self.right_padding(signal)\n",
        "    signal = self.transformation(signal)\n",
        "    return signal , label\n",
        "  \n",
        "  def _get_audio_sample_path(self,idx):\n",
        "    class_name = f\"{self.annotations.iloc[idx, 1]}\"\n",
        "    path = os.path.join(self.audio_dir, class_name, self.annotations.iloc[idx, 0])\n",
        "    return path\n",
        "  \n",
        "  def _get_audio_sample_label(self, idx):\n",
        "    return self.annotations.iloc[idx, 2]\n",
        "  \n",
        "  def resample_audio(self, signal, sr):\n",
        "    if sr != self.target_sample_rate:\n",
        "        resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
        "        signal = resampler(signal)\n",
        "    return signal\n",
        "  \n",
        "  def mix_down_channels(self, signal):\n",
        "    if signal.shape[0] > 1:\n",
        "        signal = torch.mean(signal, dim = 0, keepdim=True)\n",
        "    return signal\n",
        "  \n",
        "  def cut_if_needed(self, signal):\n",
        "    if signal.shape[1] > self.num_samples:\n",
        "        signal = signal[:, :self.num_samples]\n",
        "    return signal \n",
        "  \n",
        "  def right_padding(self, signal):\n",
        "    length_signal = signal.shape[1]\n",
        "    if length_signal < self.num_samples:\n",
        "        num_missing = self.num_samples - length_signal\n",
        "        last_dim_padding = (0, num_missing)\n",
        "        signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
        "    return signal"
      ],
      "metadata": {
        "id": "lkY-YO2r4N2p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create MEl spectrogram transformations\n",
        "SAMPLE_RATE = 48000\n",
        "NUM_SAMPLES = 240000\n",
        "\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE)"
      ],
      "metadata": {
        "id": "dGz9LayPJaTU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Custom Dataset"
      ],
      "metadata": {
        "id": "dVSiQglX7m-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ild = IndianLanguageDataset(metadata='metadata.csv', \n",
        "                            audio_dir=wav_dir, \n",
        "                            target_sample_rate=SAMPLE_RATE, \n",
        "                            transformation=mel_spectrogram,\n",
        "                            num_samples= NUM_SAMPLES)\n",
        "print(f\"there are {len(ild)} samples in the dataset\")"
      ],
      "metadata": {
        "id": "1rq28biqGrQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3acfba-1c25-4521-e95f-3249f70b59b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 28254 samples in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "specgram , label = ild[14]"
      ],
      "metadata": {
        "id": "jT1EtUDVK982"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'signal:{specgram.shape} \\n label: {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWQhd0QSLKtW",
        "outputId": "7d161c63-172d-4997-b3eb-df2dedb3f120"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signal:torch.Size([1, 128, 1201]) \n",
            " label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the spectrogram"
      ],
      "metadata": {
        "id": "58lMLre7BmZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "\n",
        "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\"):\n",
        "    fig, axs = plt.subplots(1, 1)\n",
        "    axs.set_title(title or \"Spectrogram (db)\")\n",
        "    axs.set_ylabel(ylabel)\n",
        "    axs.set_xlabel(\"frame\")\n",
        "    im = axs.imshow(specgram.squeeze(), origin=\"lower\", aspect=\"auto\")\n",
        "    fig.colorbar(im, ax=axs)\n",
        "    plt.show(block=False)"
      ],
      "metadata": {
        "id": "dta04ZF_B9JS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_spectrogram(specgram, title='MelSpectrogram')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "FmDK_0ozNC5t",
        "outputId": "c730295f-e331-49e1-c457-3d3818ba8c8a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data, sr = torchaudio.load(\"/content/final_data/language-audio-data/Hindi/Hindi1-1.wav\")"
      ],
      "metadata": {
        "id": "HdlTPL5tNLWt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN MODEL"
      ],
      "metadata": {
        "id": "VCCCMK87cyur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class ImageClassification(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "      images, labels = batch \n",
        "      out = self(images)                  # Generate predictions\n",
        "      loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "      return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "      images, labels = batch \n",
        "      out = self(images)                    # Generate predictions\n",
        "      loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "      acc = accuracy(out, labels)           # Calculate accuracy\n",
        "      return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "      batch_losses = [x['val_loss'] for x in outputs]\n",
        "      epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "      batch_accs = [x['val_acc'] for x in outputs]\n",
        "      epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "      return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "      print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "          epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "pjimD77rc0DR"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "DBBNDWigukM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNNetwork(ImageClassification):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = self.conv_block(in_channels, 16, pool=True) \n",
        "        self.conv2 = self.conv_block(16, 32, pool=True) \n",
        "        self.conv3 = self.conv_block(32, 64, pool=True) \n",
        "        self.conv4 = self.conv_block(64, 128, pool=True) \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(128 * 5 * 4, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "    @staticmethod\n",
        "    def conv_block(in_channels, out_channels, pool=False):\n",
        "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=2), \n",
        "                  nn.BatchNorm2d(out_channels), \n",
        "                  nn.ReLU(inplace=True)]\n",
        "        if pool: layers.append(nn.MaxPool2d(kernel_size=2))\n",
        "        return nn.Sequential(*layers) \n",
        "\n",
        "    def forward(self, input_data):\n",
        "        out = self.conv1(input_data)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.dropout(out)\n",
        "        logits = self.linear(out)\n",
        "        predictions = self.softmax(logits)\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "JCd-AV4Sumoc"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNNNetwork(in_channels = 1, num_classes = 4)"
      ],
      "metadata": {
        "id": "6ktyoEWkv_1t"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(cnn.cuda(), (1,62,40))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utMfRNDPwf_3",
        "outputId": "133286ac-7686-4360-9fe2-e431c725db90"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 64, 42]             160\n",
            "       BatchNorm2d-2           [-1, 16, 64, 42]              32\n",
            "              ReLU-3           [-1, 16, 64, 42]               0\n",
            "         MaxPool2d-4           [-1, 16, 32, 21]               0\n",
            "            Conv2d-5           [-1, 32, 34, 23]           4,640\n",
            "       BatchNorm2d-6           [-1, 32, 34, 23]              64\n",
            "              ReLU-7           [-1, 32, 34, 23]               0\n",
            "         MaxPool2d-8           [-1, 32, 17, 11]               0\n",
            "            Conv2d-9           [-1, 64, 19, 13]          18,496\n",
            "      BatchNorm2d-10           [-1, 64, 19, 13]             128\n",
            "             ReLU-11           [-1, 64, 19, 13]               0\n",
            "        MaxPool2d-12             [-1, 64, 9, 6]               0\n",
            "           Conv2d-13           [-1, 128, 11, 8]          73,856\n",
            "      BatchNorm2d-14           [-1, 128, 11, 8]             256\n",
            "             ReLU-15           [-1, 128, 11, 8]               0\n",
            "        MaxPool2d-16            [-1, 128, 5, 4]               0\n",
            "          Flatten-17                 [-1, 2560]               0\n",
            "          Dropout-18                 [-1, 2560]               0\n",
            "           Linear-19                    [-1, 4]          10,244\n",
            "          Softmax-20                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 107,876\n",
            "Trainable params: 107,876\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.39\n",
            "Params size (MB): 0.41\n",
            "Estimated Total Size (MB): 2.81\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU functions"
      ],
      "metadata": {
        "id": "Nt8K4b4t19cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class GPUDataLoader():\n",
        "    \"\"\"Wrap a pytorch Dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "Vdsz_2lv11jk"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training function"
      ],
      "metadata": {
        "id": "P8g-d03Q4mbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "from tqdm import tqdm\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "  model.eval()\n",
        "  outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "\n",
        "def fit(model, train_loader, val_loader, epochs, lr, opt_func):\n",
        "  history = []\n",
        "  optimizer = opt_func(model.parameters(), lr)\n",
        "  scheduler = StepLR(optimizer= optimizer, \n",
        "                  step_size = 3, \n",
        "                  gamma= 0.1)\n",
        "  for epoch in range(1, epochs+1):\n",
        "    #Training\n",
        "    print('Epoch:', epoch,'LR:', scheduler.get_last_lr())\n",
        "    train_losses = []\n",
        "    model.train()\n",
        "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
        "    for batch_idx, batch in loop:\n",
        "        loss = model.training_step(batch)\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        # backward \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # update progress bar\n",
        "        loop.set_description(f\"Epoch [{epoch}/{epochs}]\")\n",
        "        loop.set_postfix(loss = loss.item())\n",
        "\n",
        "    # validation steps\n",
        "    result = evaluate(model, val_loader)\n",
        "    result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "    model.epoch_end(epoch, result)\n",
        "    history.append(result)\n",
        "  return history"
      ],
      "metadata": {
        "id": "TI6t8-ND-yWx"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WcNzw7EjQhCn"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make stratified split of data to have same number of samples per each class"
      ],
      "metadata": {
        "id": "RMvONsO_4meB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=5, train_size=0.7, test_size=0.3, random_state=36)\n",
        "for train_index, test_index in split.split(metadata, metadata['labels']):\n",
        "    strat_train_set = metadata.loc[train_index]\n",
        "    strat_val_set = metadata.loc[test_index]\n",
        "\n",
        "strat_train_set.to_csv('metadata_train.csv', index=False)\n",
        "strat_val_set.to_csv('metadata_val.csv', index=False)"
      ],
      "metadata": {
        "id": "qSLYo73zTMaZ"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mIb-wYVVT7vM",
        "outputId": "0bff5e28-d1b1-43dc-94df-99ee91f2c7a4"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Move model objects to GPU"
      ],
      "metadata": {
        "id": "HxTtjFsS5IKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataloader, model -> GPU "
      ],
      "metadata": {
        "id": "I4RK-O_NUDt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "SAMPLE_RATE = 4000\n",
        "NUM_SAMPLES = 20000\n",
        "\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE,\n",
        "                                                  n_fft = 1024,\n",
        "                                                  hop_length = 512,\n",
        "                                                  n_mels = 64)\n",
        "# Adam optimiser\n",
        "optimser = torch.optim.Adam\n",
        "\n",
        "train_lang_data = IndianLanguageDataset(metadata='metadata_train.csv',\n",
        "                                        audio_dir = wav_dir,\n",
        "                                        target_sample_rate=SAMPLE_RATE, \n",
        "                                        transformation=mel_spectrogram,\n",
        "                                        num_samples=NUM_SAMPLES\n",
        "                                        )\n",
        "val_lang_data = IndianLanguageDataset(metadata='metadata_val.csv',\n",
        "                                       audio_dir= wav_dir,\n",
        "                                       target_sample_rate=SAMPLE_RATE,\n",
        "                                       transformation=mel_spectrogram,\n",
        "                                       num_samples=NUM_SAMPLES\n",
        "                                       )\n",
        "\n",
        "train_dl = DataLoader(dataset=train_lang_data,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4,\n",
        "                      pin_memory=True)\n",
        "\n",
        "val_dl = DataLoader(dataset=val_lang_data,\n",
        "                      batch_size=BATCH_SIZE*2,\n",
        "                      num_workers=4,\n",
        "                      pin_memory=True)"
      ],
      "metadata": {
        "id": "OkmIH7lHUHV9"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ3_DGshUHfB",
        "outputId": "3512d2cf-9b5b-4b99-f18b-3eadea9259f0"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move model to device\n",
        "model = to_device(CNNNetwork(1, 4), device)\n",
        "\n",
        "train_dl = GPUDataLoader(train_dl, device)\n",
        "val_dl = GPUDataLoader(val_dl, device)"
      ],
      "metadata": {
        "id": "eVplsK_JXabc"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "wibUOtu94--N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, val_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se_cuYKLXvfo",
        "outputId": "2eb90567-6fd6-42d3-a862-f401b4ffa3b9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': 1.5083842277526855, 'val_acc': 0.17486651241779327}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(model=model, train_loader=train_dl, val_loader=val_dl, epochs=5, lr=0.01, opt_func=optimser)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0ZAA06JhvAv",
        "outputId": "cf2a9af0-0fcf-43e2-acf2-6e0908069223"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 LR: [0.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], train_loss: 1.2470, val_loss: 1.2447, val_acc: 0.4531\n",
            "Epoch: 2 LR: [1.0000000000000064e-105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2], train_loss: 1.2505, val_loss: 1.2437, val_acc: 0.4542\n",
            "Epoch: 3 LR: [1.0000000000000122e-208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3], train_loss: 1.2499, val_loss: 1.2449, val_acc: 0.4518\n",
            "Epoch: 4 LR: [1e-312]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4], train_loss: 1.2501, val_loss: 1.2455, val_acc: 0.4540\n",
            "Epoch: 5 LR: [0.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5], train_loss: 1.2503, val_loss: 1.2417, val_acc: 0.4547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "n4sbTumNjfFi"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading saved model"
      ],
      "metadata": {
        "id": "oy0I-XPQ1Ge1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = torch.load(\"model.pt\")"
      ],
      "metadata": {
        "id": "-8-nyrri2rhg"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = CNNNetwork(1,4) "
      ],
      "metadata": {
        "id": "LIp1EbZ123F4"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.load_state_dict(saved_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYMkwm5g2_MM",
        "outputId": "faeb4992-8fa3-4b34-c56b-cca056053f86"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "z7VqzOC31GZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le_name_mapping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVZUyRFx3SCp",
        "outputId": "700c6429-ff57-4cda-c423-356ca2ccaa52"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Hindi': 0, 'Kannada': 1, 'Tamil': 2, 'Telugu': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZCHKEbQ3SFH",
        "outputId": "efe0c227-8511-4f0d-9204-b0e72346a89c"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_input , label = val_lang_data[1000][0], val_lang_data[1000][1]"
      ],
      "metadata": {
        "id": "jbE5o_NH5Qfs"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, input, target, class_mapping):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(input)\n",
        "        predicted_index = predictions[0].argmax(0)\n",
        "        predicted = class_mapping[predicted_index]\n",
        "        expected = class_mapping[target]\n",
        "    return predicted, expected"
      ],
      "metadata": {
        "id": "xmV_dBWF5gw1"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted, expected = predict(model=model.to(device='cpu'), input= target_input.unsqueeze_(0), target=label, class_mapping=list(le_name_mapping.keys()))"
      ],
      "metadata": {
        "id": "gj8WvfvhCbLs"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"the model has predicted: {predicted} and the expected class is : {expected}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eql6b-FYC8Cm",
        "outputId": "ea51b74a-00fe-4ab0-a60b-f9a2c4b029c5"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the model has predicted: Telugu and the expected class is : Telugu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exKVGxFODVQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}